import openai
import speech_recognition as sr
import pyttsx3
import whisper

# Initialize models
openai.api_key = 'YOUR_OPENAI_API_KEY'
asr_model = whisper.load_model("base")
tts_engine = pyttsx3.init()
recognizer = sr.Recognizer()

def transcribe_audio():
    with sr.Microphone() as source:
        print("Listening...")
        audio = recognizer.listen(source)
        with open("temp.wav", "wb") as f:
            f.write(audio.get_wav_data())
        result = asr_model.transcribe("temp.wav")
        return result['text']

def generate_response(prompt):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages
    )
    return response['choices'][0]['message']['content']

def speak(text):
    print("AI:", text)
    tts_engine.say(text)
    tts_engine.runAndWait()

def main():
    print("Voice Agent is ready. Say something!")
    while True:
        try:
            user_input = transcribe_audio()
            print("You:", user_input)
            if "stop" in user_input.lower():
                speak("Goodbye!")
                break
            response = generate_response(user_input)
            speak(response)
        except Exception as e:
            print("Error:", e)
            speak("Sorry, I didn't catch that.")

if __name__ == "__main__":
    main()
